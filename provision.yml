- name: ntp and create iscsi target
  hosts: iscsi_target
  become: yes
  tasks:
  - yum: name=cronyd state=absent

  - name: set timezone
    command: /usr/bin/timedatectl set-timezone Europe/Moscow

  - name: Install NTPD
    yum: name=ntp state=present

  - name: Ensure NTP is running.
    service: name=ntpd state=started enabled=yes

  - name: install targetcli
    yum: name=targetcli state=latest

  - name: create fileIO for iscsi target
    shell: targetcli /backstores/fileio create name=disk01 file_or_dev=/mnt/disk01 size=2G
   
  - name: chmod for disk01
    shell: chmod 777 /mnt/disk01
    
  - name: create IQN
    shell: targetcli /iscsi create iqn.2021-02.ru.otus:target00

  - name: create and setting iscsi target
    shell: targetcli /iscsi/iqn.2021-02.ru.otus:target00/tpg1/luns create /backstores/fileio/disk01


- name: ntp and create iscsi initiator
  hosts: node1,node2,node3
  become: yes
  tasks:
  - yum: name=cronyd state=absent

  - name: set timezone
    command: /usr/bin/timedatectl set-timezone Europe/Moscow

  - name: Install NTPD
    yum: name=ntp state=present

  - name: Ensure NTP is running.
    service: name=ntpd state=started enabled=yes

  - name: install iscsi-initiator-utils
    yum: name=iscsi-initiator-utils state=latest

  - name: chmod /etc/iscsi/initiatorname.iscsi
    shell: /usr/bin/sudo chmod 777 /etc/iscsi/initiatorname.iscsi

- name: node1 initiator
  hosts: node1
  become: yes
  tasks:
  - name: edit IQN iscsi initiator
    shell: /usr/bin/sudo echo -e "InitiatorName=iqn.2021-02.com.redhat:node1" > /etc/iscsi/initiatorname.iscsi

  - name: Check 1 path for iscsi
    command: /usr/sbin/iscsiadm -m discovery -t st -p 192.168.1.10

  - name: Check 2 path for iscsi
    command: /usr/sbin/iscsiadm -m discovery -t st -p 192.168.2.10

  - name: Check 1 and 2 path for iscsi
    command: /usr/sbin/iscsiadm -m node

- name: node2 initiator
  hosts: node2
  become: yes
  tasks:
  - name: edit IQN iscsi initiator
    shell: /usr/bin/sudo echo -e "InitiatorName=iqn.2021-02.com.redhat:node2" > /etc/iscsi/initiatorname.iscsi

  - name: Check 1 path for iscsi
    command: /usr/sbin/iscsiadm -m discovery -t st -p 192.168.1.10

  - name: Check 2 path for iscsi
    command: /usr/sbin/iscsiadm -m discovery -t st -p 192.168.2.10

  - name: Check 1 and 2 path for iscsi
    command: /usr/sbin/iscsiadm -m node

- name: node3 initiator
  hosts: node3
  become: yes
  tasks:
  - name: edit IQN iscsi initiator
    shell: /usr/bin/sudo echo -e "InitiatorName=iqn.2021-02.com.redhat:node3" > /etc/iscsi/initiatorname.iscsi

  - name: Check 1 path for iscsi
    command: /usr/sbin/iscsiadm -m discovery -t st -p 192.168.1.10

  - name: Check 2 path for iscsi
    command: /usr/sbin/iscsiadm -m discovery -t st -p 192.168.2.10

  - name: Check 1 and 2 path for iscsi
    command: /usr/sbin/iscsiadm -m node



- name: Acls on iscsi target
  hosts: iscsi_target
  become: yes
  tasks:
  - name: allow iqn iqn.2021-02.com.redhat:node1
    command: sudo targetcli iscsi/iqn.2021-02.ru.otus:target00/tpg1/acls/ create iqn.2021-02.com.redhat:node1

  - name: allow iqn iqn.2021-02.com.redhat:node2
    command: sudo targetcli iscsi/iqn.2021-02.ru.otus:target00/tpg1/acls/ create iqn.2021-02.com.redhat:node2

  - name: allow iqn iqn.2021-02.com.redhat:node3
    command: sudo targetcli iscsi/iqn.2021-02.ru.otus:target00/tpg1/acls/ create iqn.2021-02.com.redhat:node3


- name: connect to iscsi target and setting pacemaker cluster
  hosts: node1,node2,node3
  become: yes
  tasks:

  - name: connect to iscsi target
    command: /usr/sbin/iscsiadm -m node -l -T iqn.2021-02.ru.otus:target00

  - name: install multipath
    yum: name=device-mapper-multipath state=present

  - name: Ensure NTP is running.
    service: name=multipathd state=started enabled=yes

  - name: start multipath
    become: yes
    command: /usr/sbin/mpathconf --enable --with_multipathd y

  - name: edit permissions to /etc/hosts
    command: /usr/bin/chmod 777 /etc/hosts

  - name: edit to /etc/hosts
    shell: /usr/bin/sudo echo -e "192.168.1.11 node1 \n192.168.1.12 node2 \n192.168.1.13 node3" >> /etc/hosts

  - name: Install pacemaker pcs fence-agents-all
    yum: 
      name:
        - pacemaker
        - pcs
        - python3
      state: present

  - name: Ensure pcsd.service is running.
    service: name=pcsd state=started enabled=yes
  
  - name: Change password for user hacluster
    user:
      name: hacluster
      update_password: always
      password: "{{ haclusterpass |password_hash('sha512') }}"

  - name: auth cluster node
    command: pcs cluster auth node1 node2 node3 -u hacluster -p {{haclusterpass}}

  - name: create hacluster
    command: pcs cluster setup --name hacluster node1 node2 node3 --force

  - name: enable cluster
    command: pcs cluster enable --all

  - name: start cluster
    command: pcs cluster start --all

  - name: Install gfs2-utils lvm2-cluster
    yum: 
      name:
        - gfs2-utils
        - lvm2-cluster
      state: present

  #- name: Update packages
    #command: yum update -y

  - name: Enable clustered locking for LVM
    command: lvmconf --enable-cluster

  - name: reboot nodes
    reboot:

  - name: edit permissions to /etc/hosts
    command: /usr/bin/chmod 777 /etc/hosts

  - name: edit to /etc/hosts
    shell: /usr/bin/sudo echo -e "192.168.1.11 node1 \n192.168.1.12 node2 \n192.168.1.13 node3" >> /etc/hosts

  - name: start cluster
    command: pcs cluster start --all

- name: GFS2
  hosts: node1
  become: yes
  tasks:
  - name: Create DLM and CLVM
    shell: |
      pcs property set stonith-enabled=false
      pcs property set no-quorum-policy=freeze
      pcs resource create dlm systemd:dlm op monitor interval=30s on-fail=ignore clone interleave=true ordered=true
      pcs resource create clvmd ocf:heartbeat:clvm op monitor interval=30s on-fail=ignore clone interleave=true ordered=true
      pcs constraint order start dlm-clone then clvmd-clone
  
  - name: Create FS
    shell: pvcreate /dev/mapper/mpatha

  - name: vgcreate
    shell: vgcreate -Ay -cy cluster_vg /dev/mapper/mpatha

  - name: sleep 
    command: sleep 20
    
  - name: lvcreate
    become: yes
    command: sudo lvcreate -L1500M -n cluster_lv cluster_vg

  - name: mkfs.gfs2
    become: yes
    shell: sudo echo y | sudo mkfs.gfs2 -j3 -p lock_dlm -t hacluster:gfs2 /dev/cluster_vg/cluster_lv
  
  - name: create clusterfs
    become: yes
    shell: sudo pcs resource create clusterfs Filesystem device="/dev/cluster_vg/cluster_lv" directory="/mnt/gfs2" fstype="gfs2" "options=noatime" op monitor interval=10s on-fail=ignore clone interleave=true